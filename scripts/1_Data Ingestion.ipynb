{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d62eb66-d22f-4da5-b9b7-f0d0f3963c08",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Data Ingestion\n",
    "In this notebook, I will request the 2021 to 2023 daily data for the following stocks and ETFs in the Telecommunications Sector.\n",
    "* AT&T: T\n",
    "* Verizon: VZ\n",
    "* Comcast Corporation: CMCSA\n",
    "* T-Mobile US: TMUS\n",
    "* Charter Communications: CHTR\n",
    "* Dow Jones U.S. Select Telecommunications Index: DJSTEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d43b9728-1218-4448-b758-85c786460612",
     "showTitle": true,
     "title": "Imports"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Importing needed Pyspark functions\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# Importing Struct Types\n",
    "from pyspark.sql.types import StructField, StructType, DoubleType, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89181f51-a68b-43a9-a94c-d3e910ccc046",
     "showTitle": true,
     "title": "Import the API Key"
    }
   },
   "outputs": [],
   "source": [
    "%run ./Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ddeec08-9abd-467a-9242-2e6029bd261b",
     "showTitle": true,
     "title": "Function Get Stock Data"
    }
   },
   "outputs": [],
   "source": [
    "def get_data(ticker, size='compact', API_KEY = API_KEY):\n",
    "    '''\n",
    "    Function to get the stock daily historic data for a ticker from the Alpha Vantage API\n",
    "    Inputs:\n",
    "    * Ticker = Stock code: str\n",
    "    * size = 'full' for 20 years of historic data or 'compact' for the last 100 data points: str\n",
    "    \n",
    "    Returns: \n",
    "    Data frame with the stock historic data\n",
    "    '''\n",
    "      \n",
    "    # Get Data from Alpha Vantage Open API\n",
    "    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={ticker}&outputsize={size}&apikey={API_KEY}'\n",
    "    r = requests.get(url)\n",
    "    # Get only the json file output\n",
    "    data = r.json()\n",
    "    # Get only the time series, discarding the meta attribute\n",
    "    dtf = data['Time Series (Daily)']\n",
    "\n",
    "    # Transform JSON data into a list of Row objects\n",
    "    rows = [Row(date=key, **{k: float(v) if k != '5. volume' else int(v) for k, v in value.items()}) for key, value in dtf.items()]\n",
    "    \n",
    "    # Define the schema for the DataFrame\n",
    "    schema = StructType([\n",
    "        StructField(\"date\", StringType(), True),\n",
    "        StructField(\"open\", DoubleType(), True),\n",
    "        StructField(\"high\", DoubleType(), True),\n",
    "        StructField(\"low\", DoubleType(), True),\n",
    "        StructField(\"close\", DoubleType(), True),\n",
    "        StructField(\"volume\", IntegerType(), True)\n",
    "    ])\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = spark.createDataFrame(rows, schema)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9c15238-e9bf-4e78-8ca2-6b2dd4b1bfc8",
     "showTitle": true,
     "title": "Function Get Economic Indicator"
    }
   },
   "outputs": [],
   "source": [
    "def get_economic_ind(indicator, API_KEY = API_KEY):\n",
    "    '''\n",
    "    Get Economic indicator data from Alpha Vantage API\n",
    "    Indicator: str = e.g. 'REAL_GDP_PER_CAPITA', 'INFLATION'\n",
    "    '''\n",
    "    # Get Data from Alpha Vantage Open API\n",
    "    url = f'https://www.alphavantage.co/query?function={indicator}&apikey={API_KEY}'\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "        \n",
    "    # Transform to dataframe\n",
    "    df = spark.createDataFrame(data['data'])\n",
    "    print(f'{indicator} data fetched')\n",
    "    # Return\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae7d945d-39f1-4e30-98e1-f24b3e2084c0",
     "showTitle": true,
     "title": "Function Save Data"
    }
   },
   "outputs": [],
   "source": [
    "def save_data(df, ticker):\n",
    "    '''Function to save a dataframe to Databricks File System in a given file path''' \n",
    "    \n",
    "    #Error Handling\n",
    "    try:\n",
    "        # Create the path to save the file\n",
    "        path = f'/FileStore/tables/raw/{ticker}'\n",
    "        # Write file to DBFS\n",
    "        df.coalesce(1).write.format('parquet').mode('overwrite').save(path) \n",
    "        # Return success message\n",
    "        return f'{ticker} stock successfully saved to DBFS.'\n",
    "\n",
    "    except:\n",
    "        return f'Failed fetching {ticker} data.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed0966bf-7770-4cb7-8084-3d1f1e3ae701",
     "showTitle": true,
     "title": "Get Stock Tickers and Save"
    }
   },
   "outputs": [],
   "source": [
    "# Tickers to be fetched from the Alpha Vantage API\n",
    "tickers = ['TMUS', 'T', 'VZ', 'CMCSA', 'CHTR']\n",
    "\n",
    "# Extracting the Data from the API\n",
    "for ticker in tickers:\n",
    "    # Extract\n",
    "    df_extracted = get_data(ticker=ticker, size='full')\n",
    "    # Save\n",
    "    save_data(df_extracted, ticker=ticker)\n",
    "    time.sleep(2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "0671032e-800e-4ae2-913e-053d577c4b61",
     "showTitle": true,
     "title": "Get Indicators and Save"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAL_GDP_PER_CAPITA data fetched\nINFLATION data fetched\n"
     ]
    }
   ],
   "source": [
    "# Economic Indicators to be fetched from the Alpha Vantage API\n",
    "indicators = ['REAL_GDP_PER_CAPITA', 'INFLATION']\n",
    "\n",
    "# Extracting the Data from the API\n",
    "for indicator in indicators:\n",
    "    # Extract\n",
    "    df_extracted = get_economic_ind(indicator=indicator)\n",
    "    # Save\n",
    "    save_data(df_extracted, ticker=indicator)\n",
    "    time.sleep(4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b426966-2b9f-416d-8add-4ecaedcfb575",
     "showTitle": true,
     "title": "Get Telecomm Index Data from Twelve Data"
    }
   },
   "outputs": [],
   "source": [
    "# Tickers to be fetched from the Alpha Vantage API\n",
    "telco_index = 'DJUSTL'\n",
    "# Get Data from Alpha Vantage Open API\n",
    "url = f'https://api.twelvedata.com/time_series?apikey={API_TWELVE}&interval=1day&symbol={telco_index}&format=JSON&outputsize=5000'\n",
    "r = requests.get(url)\n",
    "data = r.json()\n",
    "\n",
    "# Create dataframe\n",
    "df = spark.createDataFrame(data['values'])\n",
    "\n",
    "#Save to the Raw Folder\n",
    "path = f'/FileStore/tables/raw/{telco_index}'\n",
    "# Write file to DBFS\n",
    "df.coalesce(1).write.format('parquet').mode('overwrite').save(path)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8857e348-ebd8-46e6-a027-381dccf1004d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1682598570255601,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "1. Data Ingestion",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
